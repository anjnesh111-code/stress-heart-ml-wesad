{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/stress-heart-ml-wesad\"\n"
      ],
      "metadata": {
        "id": "TF4OeaSxm1rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/stress-heart-ml-wesad\"\n",
        "DATA_DIR = f\"{PROJECT_ROOT}/data/processed\"\n",
        "RESULTS_DIR = f\"{PROJECT_ROOT}/results\"\n",
        "\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Project directories ready ✅\")\n"
      ],
      "metadata": {
        "id": "PRUJUMW8mSVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mITCil_JldaJ"
      },
      "outputs": [],
      "source": [
        "def build_subject_dataset(pkl_path, subject_id):\n",
        "    \"\"\"\n",
        "    Takes a WESAD subject .pkl file\n",
        "    Returns ML-ready dataframe for that subject\n",
        "    \"\"\"\n",
        "\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from scipy.signal import butter, filtfilt, find_peaks\n",
        "\n",
        "    # ------------------\n",
        "    # Load data\n",
        "    # ------------------\n",
        "    with open(pkl_path, \"rb\") as f:\n",
        "        data = pickle.load(f, encoding=\"latin1\")\n",
        "\n",
        "    signals = data[\"signal\"][\"wrist\"]\n",
        "    labels  = data[\"label\"]\n",
        "\n",
        "    eda = signals[\"EDA\"].squeeze()\n",
        "    bvp = signals[\"BVP\"].squeeze()\n",
        "\n",
        "    # ------------------\n",
        "    # EDA preprocessing\n",
        "    # ------------------\n",
        "    def lowpass(data, cutoff=0.5, fs=4, order=4):\n",
        "        nyq = 0.5 * fs\n",
        "        b, a = butter(order, cutoff/nyq, btype=\"low\")\n",
        "        return filtfilt(b, a, data)\n",
        "\n",
        "    eda_f = lowpass(eda)\n",
        "\n",
        "    # ------------------\n",
        "    # BVP preprocessing\n",
        "    # ------------------\n",
        "    def bandpass(data, low=0.67, high=3.5, fs=64, order=3):\n",
        "        nyq = 0.5 * fs\n",
        "        b, a = butter(order, [low/nyq, high/nyq], btype=\"band\")\n",
        "        return filtfilt(b, a, data)\n",
        "\n",
        "    bvp_f = bandpass(bvp)\n",
        "\n",
        "    # ------------------\n",
        "    # Windowing\n",
        "    # ------------------\n",
        "    def sliding_windows(x, fs, win=60, step=30):\n",
        "        w = int(win * fs)\n",
        "        s = int(step * fs)\n",
        "        return [x[i:i+w] for i in range(0, len(x)-w, s)]\n",
        "\n",
        "    eda_wins = sliding_windows(eda_f, fs=4)\n",
        "    bvp_wins = sliding_windows(bvp_f, fs=64)\n",
        "\n",
        "    # ------------------\n",
        "    # Label windows\n",
        "    # ------------------\n",
        "    def window_labels(lbl, fs=700, win=60, step=30):\n",
        "        w = int(win * fs)\n",
        "        s = int(step * fs)\n",
        "        y = []\n",
        "        for i in range(0, len(lbl)-w, s):\n",
        "            y.append(np.bincount(lbl[i:i+w]).argmax())\n",
        "        return y\n",
        "\n",
        "    y = window_labels(labels)\n",
        "\n",
        "    # ------------------\n",
        "    # Feature extraction\n",
        "    # ------------------\n",
        "    rows = []\n",
        "\n",
        "    for e, b in zip(eda_wins, bvp_wins):\n",
        "        # EDA features\n",
        "        eda_n = (e - e.min()) / (e.max() - e.min() + 1e-8)\n",
        "        peaks, _ = find_peaks(eda_n, height=0.1, distance=5)\n",
        "\n",
        "        scr_count = len(peaks)\n",
        "        scr_amp   = np.mean(eda_n[peaks]) if len(peaks) else 0\n",
        "\n",
        "        # HRV features\n",
        "        bp, _ = find_peaks(b, distance=64*0.4, prominence=0.2)\n",
        "        if len(bp) < 3:\n",
        "            continue\n",
        "\n",
        "        rr = np.diff(bp) / 64\n",
        "\n",
        "        rows.append({\n",
        "            \"mean_HR\": np.mean(60/rr),\n",
        "            \"RMSSD\": np.sqrt(np.mean(np.diff(rr)**2)),\n",
        "            \"SDNN\": np.std(rr),\n",
        "            \"SCR_count\": scr_count,\n",
        "            \"SCR_amp\": scr_amp\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Align labels\n",
        "    min_len = min(len(df), len(y))\n",
        "    df = df.iloc[:min_len]\n",
        "    df[\"label\"] = y[:min_len]\n",
        "\n",
        "    # Map labels + clean\n",
        "    label_map = {1:0, 2:1, 3:2}\n",
        "    df[\"label\"] = df[\"label\"].map(label_map)\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "    print(f\"✅ Subject {subject_id}: {df.shape[0]} windows\")\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_S2_ml = build_subject_dataset(\"/root/.cache/kagglehub/datasets/mohamedasem318/wesad-full-dataset/versions/2/WESAD/S2/S2.pkl\", \"S2\")\n",
        "df_S3_ml = build_subject_dataset(\"/root/.cache/kagglehub/datasets/mohamedasem318/wesad-full-dataset/versions/2/WESAD/S3/S3.pkl\", \"S3\")\n"
      ],
      "metadata": {
        "id": "znpEnX44lmpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_S2_ml.drop(columns=[\"label\"])\n",
        "y_train = df_S2_ml[\"label\"]\n",
        "\n",
        "X_test  = df_S3_ml.drop(columns=[\"label\"])\n",
        "y_test  = df_S3_ml[\"label\"]\n"
      ],
      "metadata": {
        "id": "viEtCyHplqA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "opSyhc6Mltde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf.fit(X_train_scaled, y_train)\n"
      ],
      "metadata": {
        "id": "SHKFElI_lwQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_pred = rf.predict(X_test_scaled)\n",
        "\n",
        "print(\"Cross-subject Accuracy (S2 → S3):\",\n",
        "      accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\\n\",\n",
        "      classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "b2jPX7Pklync"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}